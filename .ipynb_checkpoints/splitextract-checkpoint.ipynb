{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os, pickle\n",
    "import requests, glob\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "import urllib.request\n",
    "from selenium.webdriver import Chrome\n",
    "import json, re, sys, h5py\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import datetime as dt\n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from pykrx import stock\n",
    "import pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitExtract:\n",
    "    def __init__(self):\n",
    "        \"\"\"Naver Finance : Financial Summary Crawler\"\"\"\n",
    "        self.driver_path = \"C:/Users/Bae Kyungmo/OneDrive/Desktop/WC_basic/chromedriver.exe\"\n",
    "        self.update_date = datetime.today().strftime('%Y-%m-%d')\n",
    "        self.conn = pymysql.connect(host='localhost',user='root',\n",
    "                                   password='tlqkfdk2',db='INVESTAR',charset='utf8')\n",
    "        with self.conn.cursor() as curs:\n",
    "            sql_load = \"\"\"\n",
    "            SELECT CODE, COMPANY FROM COMPANY_INFO\n",
    "            \"\"\"\n",
    "            curs.execute(sql_load)\n",
    "            comps_ls = curs.fetchall()\n",
    "            self.codes = [str(e[0]) for e in comps_ls]\n",
    "            self.comps = [str(e[1]) for e in comps_ls]\n",
    "\n",
    "        self.conn.commit() # May not be needed..        \n",
    "        self.url = 'https://finance.naver.com/item/fchart.nhn?code={}'\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Disconnecting MariaDB\"\"\"\n",
    "        self.conn.close()\n",
    "        \n",
    "    def Extractor(self,n,m):\n",
    "        #total = pd.DataFrame(columns=['code','company','split_info'])\n",
    "        total_ls = []\n",
    "        errors = []\n",
    "        browser = Chrome(self.driver_path)\n",
    "        browser.maximize_window()\n",
    "        for ii, cd in enumerate(self.codes[n:m]) :\n",
    "            try :\n",
    "                sub_ls = []\n",
    "                split_info = ''\n",
    "                browser.get(self.url.format(cd))\n",
    "                for _ in range(5):\n",
    "                    browser.find_elements_by_xpath('//*[@id=\"content\"]/div[2]/cq-context/div[1]/div[2]/div/div[2]/div[1]')[0].click()\n",
    "                for _ in range(10):\n",
    "                    pyautogui.moveTo(369, 899)\n",
    "                    pyautogui.dragTo(1064,899, 1, button='left')\n",
    "                html = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "                html_div = html.find_all('div',attrs={\"class\":\"scheduleMarker dividend\"})\n",
    "                for idx in range(len(html_div)):\n",
    "                    if html_div[idx].text != '':\n",
    "                        if idx != 0 :\n",
    "                            split_info += '-'\n",
    "                        split_info += html_div[idx].text\n",
    "                sub_ls.append(cd)\n",
    "                sub_ls.append(self.comps[ii])\n",
    "                sub_ls.append(split_info)\n",
    "                total_ls.append(sub_ls)\n",
    "            except :\n",
    "                errors.append(cd)\n",
    "        total = pd.DataFrame(data=total_ls, columns=['code','company','split_info'])\n",
    "        return total, errors\n",
    "    \n",
    "    def DBSave(self, df):\n",
    "        errs = []\n",
    "        cursor = self.conn.cursor()\n",
    "        sql = \"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS split_info (\n",
    "                code VARCHAR(20),\n",
    "                company VARCHAR(40),\n",
    "                split VARCHAR(100),\n",
    "                PRIMARY KEY (code))\n",
    "            \"\"\"\n",
    "        cursor.execute(sql)\n",
    "        self.conn.commit()\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            if len(pd.read_sql(f\"select * from split_info where code='{row.code}' and company='{row.company}'\", self.conn)) == 0 :\n",
    "                try :\n",
    "                    #print(f\"INSERT INTO split_info (code,company,split) values({row.code},{row.company},{row.split_info})\")\n",
    "                    cursor.execute(f\"INSERT INTO split_info values('{row.code}','{row.company}','{row.split_info}')\")\n",
    "                    self.conn.commit()\n",
    "                except :\n",
    "                    if len(df[lambda x : x['code']==row.code].split_info.values[0]) >= 15 : #rough하게 VARCHAR(40) 안 넘도록\n",
    "                        short_info = '폭발|' + df[lambda x : x['code']==row.code].split_info.values[0][-15:]\n",
    "                        cursor.execute(f\"INSERT INTO split_info values('{row.code}','{row.company}','{short_info}')\")\n",
    "                        self.conn.commit()\n",
    "                    else :\n",
    "                        errs.append(row)\n",
    "        print(\"Uploading to DB is successfully finished.\")\n",
    "        return errs #\"Uploading to DB is successfully finished.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SplitExtract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to DB is successfully finished.\n",
      "Wall time: 7h 18min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# 자기전에 돌려야함.. 전체로..\n",
    "rst, ers = ss.Extractor(n=180,m=1800)\n",
    "dbers = ss.DBSave(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# 자기전에 돌려야함.. 전체로..\n",
    "rst, ers = ss.Extractor(n=1800,m=2411)\n",
    "dbers = ss.DBSave(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading to DB is successfully finished.\n",
      "Wall time: 56min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# 이거 돌리면 끝임\n",
    "rst, ers = ss.Extractor(n=2190,m=2411)\n",
    "dbers = ss.DBSave(rst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
